% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage[noblocks]
{authblk}
\renewcommand*{\Authsep}{, }
\renewcommand*{\Authand}{, }
\renewcommand*{\Authands}{, }
\renewcommand\Affilfont{\small}
\DeclareMathOperator*{\argmin}{arg\,min}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Measuring the economic reasoning abilities of language models(Preliminary and incomplete)},
  pdfauthor={Douglas K. G. Araujo},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Measuring the economic reasoning abilities of language
models\newline(Preliminary and incomplete)\thanks{This work represents
my opinion and not necessarily that of the BIS.}}


  \author{Douglas K. G. Araujo}
            \affil{%
                  Bank for International
Settlements, douglas.araujo@bis.org
              }
      
\date{}
\begin{document}
\maketitle
\begin{abstract}
Economic reasoning is represented as a state space function.
\end{abstract}

\section{Introduction}\label{introduction}

Language models (LMs), in particular those classified as generative
artificial intelligence (gen AI), are finding increasing uses in finance
and economics. These models are usually tested for their ability to
reason, and seem to do well: for example, OpenAI's GPT-4 boats more than
80\% correct results in academic and professional micro- and
macroeconomics tests (Achiam et al. (2023)). Still, even such advanced
models can fail miserably. Perez-Cruz and Shin (2024) demonstrate how
the same model can correctly solve a logical puzzle requiring reasoning
about higher order knowledge, only to fail when irrelevant details are
changed. Building on results such as this and other examples that
clearly illustrate the limits of rationality assumptions on LMs, this
work discusses how to systematically measure \emph{economic} reasoning,
combining literatures on economic thought and on computer science about
gen AI benchmarking. In practical terms, the task at hand is to come up
with testing mechanisms that estimate the level of economic reasoning of
an LM by means of a prompt consisting of \(n \geq 0\) examples and a
question with multiple answers.

At its most essential form, testing for economic reasoning is the same
as probing if the model is able to think in terms of logical operators.
However, they can be subjective because (a) economic thought is always
changing and (b) they are only as good as their abilites ot explain
limited sets of reality (those that modern academics constantly see=
rather than any other reality).

Similar to many other social disciplines, economics requires the
analytical judgment referred to by Robbins (1932) in the analyses of
events as a basis to extrapolate and predict, and this has a bearing on
how economic reasoning should be benchmarked. Economic inference depends
primarily on articulating unobservable quantities, theorecised and
estimated on the basis of observable measures. This is unlike other
major disciplines. For example, in human and veterinary medicine, all
physiological and pathological variables of clinical importance are
observable, even if that is not yet technologically feasible today. In
the medical sciences, theoretical models merely fill in the gaps in the
absence of a technologically feasible complete measurement. In contrast,
many economically relevant quantities are latent variables that cannot
by definition be observed, and always require a model applied to data to
be estimated, implicit or not.

A quantitative test for economic reasoning must take this into account:
selecting a correct answer in an economics question through reasoning
will always depend on an unobserved transformation of the information
received and the existing knowledge. This is important. LMs may also
happen to choose the correct answer from either luck of through simple
token probability. It is easy to see why a correct answer selected by
chance is not informative about the reasoning abilities of a model. The
second case requires more explanation: mathematically, LMs are trained
to identify the most likely token \(\theta\) in a vocabulary \(V\) given
the tokens in its prompt. In practice, the function is inexcrutable so
it is also considered an unobservable transformation. But a few
characteristics allows us to distinguish reasoning from prediction.
First, reasoning is robust to minutiae and other irrelevant detail.
Mathematically, it would be analogous to applying a manifold
transformation that retains only the relevant information in a prompt
and then applies logic operations on top of them, and on them only.
Second, reasoning is locally complete, meaning that an LM that can
correctly deduce that A implies B also is able to understand that A'
does not imply B, or that A does not imply B'. In other words, a
reasoning that appears to be correct but whose obvious corolary is not
achieved by an LM cannot be said to have been reasoned in the first
place.

Knowledge: linguistic, common and commonsense.

Interpretation. information theory. Shannon.

The main intuition of this work is to combine a number of building
blocks of evaluation.

\begin{itemize}
\item
  the benchmark must be challenging for machines: I use an adjusted
  version of adversarial filtering (Zellers et al. (2019)) to create
  answer candidates that are hard for LMs to guess
\item
  the test must incorporate slow-moving evolutions in academic economic
  thought: evolving test set based on newly published academic work.
\item
  results related to reasoning must be distinguished as best as possible
  from the ability to interpret the prompt or from knowledge (implicit
  or explicit) about economics, ie reasoning is a separate step: sets of
  perturbations in the spirit of Alzahrani et al. (2024) for each
  initial task.
\end{itemize}

the benchmark counts with a mathematical adjustment that takes into
account performance across perturbations, penalising results that vary
with \ldots.

This benchmark evaluation addresses a poignant issue for the economics
profession: the lack of publicly available data about how these
benchmarks are created and any, and toasted.

A major inspiration in the design of the questions and how they can
generate identifying variations is the social economics literature. A
key reference is Stantcheva (2023). The idea here is that the design of
the questionnaire itself can elicit responses that allow for insight
into non-observable traits such as reasoning. Many of the insights of
this literature carry over naturally to the machine space.\footnote{Actually
  testing whether LMs \emph{do not} parrot or ``organically'' exhibit
  biases or other behaviours that are assumed to be exclusively human
  would be an interesting line of research.}

\subsection{Literature}\label{literature}

Four streams of literature.

Benchmarking\ldots{} A substantial body of work creates and discusses
benchmarking models in general. A very useful reference is Storks, Gao,
and Chai (2020). Literature on benchmarking economic reasoning appears
to be new, although other works have touched upon the topic from
different angles.

Social economics\ldots{}

Reasoning itself\ldots{}

A nascent literature on the evaluation of language models in economic
settings. An early foray into questions related to AI's ability to
conduct economic reasoning is due to Parkes and Wellman (2015). But
their angle is more on how AIs can be used to estimate synthetic
economic agents - machina oeconomicus - ideal versions of purely
rational agents, rather than on the measurement and the implications of
AIs acquiring economic reasoning abilities. In any case, Parkes and
Wellman (2015) see economic reasoning as the ability to understand and
solve complex game-theoretical environments (eg, the poker example). Mei
et al. (2024) do an extensive comparison of personality traits from the
behaviour of ChatGPT with human behaviour in games that require
cooperation, finding that its performance is consistent with humans, and
when it deviates the AI models tend to behave in the altruistic and
cooperative than the mass distribution of humans. Interestingly, ChatGPT
responds differently to different formulations of the same situation. In
contrast to Mei et al. (2024), this paper and its empirical counterpart
are more generall, and discuss reasoning as a whole. Another contrast to
that paper is that the current benchmark is focused on reasoning ability
only, not personality. Perez-Cruz and Shin (2024) illustrate the
brittleness of a leading AI's reasoning, which has markedly lower
performance when trivial details in the prompts are different.
Similarly, Korinek (2023) report (in his Chat 23) that results from a
technical prompt in economics are reasonable but also brittle, with
answers changing when prompt wording changes or even simply if the tasks
are re-ordered.

\section{Lessons from human surveys}\label{lessons-from-human-surveys}

I use a considerable amount of specific advice on human surveys from
Stantcheva (2023) to generate identifying variation in the questions.
Specifically:

\begin{itemize}
\tightlist
\item
  coeteris paribus questions
\item
  pre-testing
\item
  including possibilities for blank, indifferent or even recognise that
  AI does not know
\item
  avoiding jargon
\item
  questions that check for ``attention'' and ``effort'' on the part of
  the respondent
\item
  also including open ended questions (as in Ferrario and Stantcheva
  (2022))

  \begin{itemize}
  \tightlist
  \item
    including follow-up questions (``are thre any other reasons'')
  \item
    going beyond Ferrario and Stantcheva (2022), in this paper I use
    open ended questions that are similar in nature to closed end
    questions and deploy large language models to interpret them.
  \end{itemize}
\item
  question ordering

  \begin{itemize}
  \tightlist
  \item
    in particular, consideration is given to whether each question
    should be presented to a separate instance of the LM, or the full
    questionnaire could be shared in the same ``chat''.
  \end{itemize}
\item
  take due consideration of how to address the different types of bias
  associated with surveys (adapted for the machine context, naturally)
\end{itemize}

\section{Desirable characteristics of a
benchmark}\label{desirable-characteristics-of-a-benchmark}

\subsection{Evolve over time}\label{evolve-over-time}

Economic reasoning evolves over time. For example, the Lucas critique
(Lucas (1976)) was influential in shifting macroeconomic modelling,
while the credibility revolution described in Angrist and Pischke (2008)
was similarly influential in microeconomic work. Debreu (1984) describes
the evolution of economic theory up until that point.

\section{A model of economic
reasoning}\label{a-model-of-economic-reasoning}

The result from existing benchmarks is largely, if not completely,
directly related to the number of questions correctly answered. However,
this measures only the model's ability to answer correctly, \emph{not
necessarily} its reasoning capabilities. The latter are part of a latent
state space sitting between the input prompt and the answer. More
concretely, for an input prompt \(X\), which includes a question and any
necessary explicit information, the language model is a function
\(\mathbf{M}\) that maps it to a given response:
\(\mathbf{M} : X \to y\). In order to show that it is done by reasoning,
we need tests (and more specifically, measurements) that convey some
information about the inner workings of this function.

\subsection{Reasoning as an abstract of the
input}\label{reasoning-as-an-abstract-of-the-input}

\begin{itemize}
\item
  Input prompt \(X\)
\item
  Transformed into \(g(X, \kappa)\), a state space function that also
  takes the existing knowledge \(\kappa\) and associates it with the
  prompt to maps it to its abstract fundamentals (similar to manifold
  learning)
\item
  Result based on \(g(X)\).
\end{itemize}

\subsection{A (very) simple model}\label{a-very-simple-model}

This section builds on the intuition that in true reasoning, the result
should be robust to minute perturbations, ie the model is a constant
function over the domain of the input. Formally, both
\(\mathbf{M}(X) = y\) and \(\mathbf{M}(X + \epsilon) = y\) for an
infinitesimal \(\epsilon\). This implies the derivative with respect to
the input prompt is zero. Using as an approachable example the simplest
possible neural network, the logistic regression
\(\mathbf{N}(x) = \sigma(Wx + b)\), such robustness further implies that
\(\frac{d\mathbf{N}}{d x} = \sigma(Wx + b)(1-\sigma(Wx + b))W = 0\).
Because \(W\) cannot be a zero vector in a functioning network that is
responsive to its inputs and \(\sigma(Wx + b)(1-\sigma(Wx + b)) = 0\)
has no solution because neither term is 0 or 1 in a sigmoid function
with finite inputs, the neural network cannot be a constant function.
This extremely simplified example, which holds for recursive
architectures of similarly simple layers, does not bode well for the
robustness of results given small perturbations in the input prompt.

\section{Reasoning benchmarks in other
fields}\label{reasoning-benchmarks-in-other-fields}

\begin{itemize}
\item
  Math
\item
  Medical
\item
  Biologia
\end{itemize}

\section{A model of reasoning}\label{a-model-of-reasoning}

This section develops a model of reasoning that fits naturally into both
natural and artificial LMs. It will serve as the basis for the
subsequent analyses and empirical creation of a reasoning benchmark.

Let a sentence \(\mathbf{S} = (\theta_1, \theta_2, \theta_3, ...)\) be a
sequence of token-location tuples \(\theta_x = (\tau, x)\), with each
\(\tau \in \mathbf{V}\) belonging to a vocabulary \(\mathbf{V}\) and
\(x \in \mathbb{N}^{d_{\text{model}}}\).\footnote{The location is
  important because it helps define meaning, along with the actual
  letter (more generally, symbol) content of th token. Note that in this
  paper, white spaces are abstracted away for expositional simplicity.}
Create a function \(\pi_{i, C} : \theta, \mathbf{S} \to \{-1, 0, 1\}\)
that maps each token into one of three possibilities: the token's
information can be considered a adversarial (-1), irrelevant (0) or
relevant (1) with respect to the likelihood of individual (or LM) \(i\)
uttering another sentence C. For example, take the following quote from
the character Barf in the 1987 movie Spaceballs, organised as two
sentences ``I'm a mog. Half man, half dog.'' and ``I'm my own best
friend.'' With word-level tokenisation,
\(\mathbf{S} = \{("\text{I'm}", 1), ("\text{a}", 2), ("\text{mog}", 3), ("\text{.}", 4), ("\text{Half}", 5), ("\text{man}", 6), ("\text{,}", 7), ("\text{half}", 8), ("\text{dog}", 9), ("\text{.}", 10)\}\)
and \(\mathbf{C}\) is similarly broken down. This example illustrates
that even when there is not a logical connection grounded in truth,
tokens in one sentence - even those made up like ``mog'', can have a
bearing on the likelihood of tokens appearing in another sentence. This
likelihood can differ depending on the location of the token, which also
allows for situations where repeteating of a word \(\tau\) is meant to
convey different meaning. Another feature of this example is that all
\(\pi_{\text{Barf}, C}(\theta) = 1 \forall \theta \in \mathbf{S}\). In
the alternative sentence ``I'm a mog. Half man, half dog. I am alive.'',
the new component is obviously irrelevant for \(\mathbf{C}\):
\(\prod_{x \in [10, 14]} \pi_{\text{Barf}, C}(\theta_x) = 0\).

This exposition is important to delve into the reasoning aspect,
entirely organised by function \(\pi\). Since \(\pi_{i, C}\) measures
how informative a token is for individual \(i\)'s \(\mathbf{C}\), it
constitutes the first aspect of reasoning: to recognise when a token is
adversarial, irrelevant or relevant. This step is necessary before the
application of any logical rules \(\mathcal{l} \in \mathcal{L}\) on the
weighted token, \(\pi_{i, C}(\theta_x) \theta_x\). The exact
underpinnings of these logical rules are beyond the scope of this work -
it can be approximated by a possibly non-linear function, \(g\). What
suffices in this work is to say that reasoning \emph{depends} on
correctly classifying the tokens: all relevant tokens must be so
identified, lest they be either ignored as the irrelevant ones or taken
with the opposite meaning. Similarly, if all relevant tokens are indeed
diagnosed correctly but other tokens are also diagnosed as relevant when
they are not, then this will cause problems for the correct reasoning.
In other words, a first precondition for reasoning is to have a low
categorical cross-entropy loss. Intuitively, a pre-condition of
reasoning is to correctly interpret the inputs.

Use Taylor expansion on model since its derivative to perturbation
should be zero. This gives us a head start in the Taylor expansion. Try
to link the T-expanded equation to an estimating equation.

But what determines \(\pi_{i, C}\)? A combination of knowledges and
logical relationships.

Knowledges: linguistic knowledge, common knowledge and commonsense
knowledge

Rationales: reasoning from logic

Armed with the sentence-level categorical cross-entropy, the individual
can establish chains of thought that will finally lead to reasoning.
Again, for simplicity, the exact function is not discussed here, other
than that it is a potentially simple or complex way to interact. What is
important is to add the categorical cross-entropy to the estimation
equation.

\textbf{Benchmark testing mechanism}\ldots{}

\subsection{The importance of manifold for
reasoning}\label{the-importance-of-manifold-for-reasoning}

The first step, interpreting the received impulses (ie, the prompts),
involve correctly judging what is relevant and what is not relevant.
This is similar for example to how the brain receives an incredible
amount of sensory inputs but chooses to focus only on those that are
more relevant instead of being overwhelmed with everything else, an
observation that has inspired dimensionality-reduction algorithms (eg,
isometric mapping, or IsoMap, by Tenenbaum, Silva, and Langford (2000)
describes how to find global optima while also defining the (much lower)
degrees of freedom in a high-dimensional input).

For example, Pope et al. (2021) study the intrinsic underlying
dimensionality of the manifold of image datasets and find them to be
significantly lower. In practice, inputs can even be said to be
\emph{union of manifolds} (as verified by Brown et al. (2022) with image
datasets in an exercise similar to the one by Pope et al. (2021)), which
means that each manifold has its own intrinsic dimensionality that is
not forced upon the other manifolds. This perspective affords
flexibility in the interpretation of identifying variations because they
don't necessarily need to probe the same dimensions at each task.

In econometrics, Andrews and Mikusheva (2016).

\subsection{Reasoning iself as a
manifold}\label{reasoning-iself-as-a-manifold}

Since proper reasoning needs to be insensitive to unimportant details,
and the vector of changes depends on logical relationships between
components, the set of all ``reasonable'' constructions is not obtained
at random but reflects this lower-dimensional, underlying structure,
similar to how random pixels would only rarely form human faces.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\end{enumerate}

Gilboa et al. (2014) argues why economic reasoning works in the way of
creating simple, positively wrong but conceptually useful
representations of reality, even when economics is studying particular
cases. A marked characteristic of such models is their preference for
simplicity, a theme also explored by Gilboa and Schmeidler (2010), who
study the matching of economic theories to empirical data, generalising
the evaluation of how reasonable a theory is through a combination of
their likelihood (or goodness-of-fit) with a penalising factor for their
complexity. Intuitively, this simplicity in reasoning is suggestive of
the manifold hypothesis in reasoning as well.

Gilboa, Minardi, and Wang (2023) sees rationality, or reasoning, also as
a robustness to trivial detail, and also discuss different types of
reasoning (subjective reasoning, etc).

\section{Reasoning about economics}\label{reasoning-about-economics}

The model above allows us to estimate reasoning while also breaking down
some of its components to better understand them. For example, we can
estimate any errors in reasoning into an issue with
\textbf{interpretation}, \textbf{knowledge} and \textbf{logical
thinking}. The empirical estimation follows.

Gilboa et al. (2022) distinguish between three types of inquity in
economic theory: economics itself (analysis of economic phenomena),
development of economic methods (the development of analytical tools
needed to study economic phenomena) and the methodology of economics
(the research/scientific endeavour in economics, including but not
limited to theory).\footnote{In fact, Gilboa et al. (2022) even allude
  to the blurred lines between economics and the philosophy or sociology
  of economics. I don't go ino these differences here.}

\section{Empirical estimation}\label{empirical-estimation}

Each \emph{task} \(\theta \in \Theta\) can be asked in various different
ways, each one being called a \emph{question} \(q \in \theta\).
Questions vary with respect to their adversarial aspect; it is this
variation within each question that allows the empirical estimation of
the effects associated with interpretation or with knowledge. Most of
the variations are originally those tested in Alzahrani et al. (2024).
The variation in response between the questions within each task will
comprise the evaluation of the actual reasoning capabilities. As alluded
to before, the variations are organised into those that measure the
stability of a response to adversarial interpretation answers, and those
that measure the stability across the knowledge dimension. In practice,
each task has hundreds of different \(q\). These groups are described in
more detail next.

\subsection{Variations related to
interpretation}\label{variations-related-to-interpretation}

There are several classes of variations that can help test an LMs'
interpretation.

\subsubsection{Choice variations}\label{choice-variations}

Here the choices remain the same for a task but vary in their order
across questions

\begin{itemize}
\item
  random choice order
\item
  biased choice order
\item
  uncommon answer choice symbols
\item
  common but unordered answer choice symbols
\end{itemize}

\subsubsection{Word variations}\label{word-variations}

The main idea here is to introduce or change words that are irrelevant.
This is along the lines of the test conducted by Perez-Cruz and Shin
(2024).

Another one is to conduct random word repetition as if it were a typo

\subsection{Variations related to
knowledge}\label{variations-related-to-knowledge}

Changing key words related to field knowledge with other field knowledge
words but that would not make a sense to an expert. This can be compared
with just changing the same words into another generic word. Comparing
responses between both should indicate the level of knowledge used by
the model (should it? need to think more)

\subsection{Estimation formula}\label{estimation-formula}

The main formula is akin to the linear probability model since \(a_{q}\)
is either zero or one:

\[
a_{q} = \beta_{\theta} \theta + \beta_{\text{Interpretation}} \eta_q + \beta_{\text{Knowledge}} \kappa_q + \epsilon_q
\]

Another idea to explore is whether these variations can actually
instrument interpretation and knowledge. This would allow the formula to
estimate the reasoning bit.

\section{Operational characteristics}\label{operational-characteristics}

\begin{itemize}
\tightlist
\item
  avoid becoming part of training data
\end{itemize}

Some drawbacks of using academic papers include:

\begin{itemize}
\tightlist
\item
  bias to report only positive findings (and to do so in a way that is
  generous towards said findings)
\item
  Also, academic papers suffer from false negatives: many contributions
  that are now considered classics have been previously rejected (Gans
  and Shepherd (1994)).
\end{itemize}

\section{Conclusions}\label{conclusions}

As economic agents and policymakers harness generative artificial
intelligence (AI) to reap considerable efficiencies, and thus their
societal footprint becomes larger, a benchmark for economic reasoning is
needed. I suggest ways to implement such a benchmark, and measure the
current performance of a selected list of LMs.

Let me conclude with Ken Arrow's impossibility theorem (CITE), or rather
the story of how he achieved this incredibly influential result. Arrow
first attempted to improve upon two-century-old Condorcet's paradox, and
studied ways in which individual preferences could be aggregated while
satisfying some intuitive conditions. It was only through repeated
failures to do so that he switched the focus to attempting to prove its
impossibility. While Arrow can be safely used as a prime example of
economic reasoning, the point this anecdote illustrates is that
breakthroughs in economic knowledge require also inspiration (in this
case from the appeal of addressing Condorcet's paradox) as well as
persistence and ability to change one's focus. The current work focuses
on developing robust benchmarks of models' reasoning abilities in
economics; further work exploring their contributions to
inspiration\footnote{Korinek (2023) illustrates use of AI models to help
  economists have new ideas for work.} and to methodological assistance
(as in the example to change focus) are also warranted for a more
complete assessment of models' abilities to provide cognitive support to
human economists.

\section{Annex 1: discussion of biases in human surveys and how they
could affect LM
questionnaires}\label{annex-1-discussion-of-biases-in-human-surveys-and-how-they-could-affect-lm-questionnaires}

\begin{itemize}
\tightlist
\item
  Section A-4 in Stantcheva (2023)
\end{itemize}

The goal of this annex is to list side-by-side the main human biases
that affect survey responses and their corresponding machine version, if
any (from a theoretical perspective - it would be interesting to test if
LMs carry over some of these biases that are supposed to be only human,
which could suggest they are parroting or in extremis developing sources
of bias like shame, etc).

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-achiam2023gpt}
Achiam, Josh, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya,
Florencia Leoni Aleman, Diogo Almeida, et al. 2023. {``Gpt-4 Technical
Report.''} \emph{arXiv Preprint arXiv:2303.08774}.

\bibitem[\citeproctext]{ref-alzahrani2024benchmarks}
Alzahrani, Norah, Hisham Abdullah Alyahya, Yazeed Alnumay, Sultan
Alrashed, Shaykhah Alsubaie, Yusef Almushaykeh, Faisal Mirza, et al.
2024. {``When Benchmarks Are Targets: Revealing the Sensitivity of Large
Language Model Leaderboards.''} \emph{arXiv Preprint arXiv:2402.01781}.

\bibitem[\citeproctext]{ref-andrews2016geometric}
Andrews, Isaiah, and Anna Mikusheva. 2016. {``A Geometric Approach to
Nonlinear Econometric Models.''} \emph{Econometrica} 84 (3): 1249--64.

\bibitem[\citeproctext]{ref-angrist2008mostly}
Angrist, Joshua D., and Jörn-Steffen Pischke. 2008. \emph{Mostly
Harmless Econometrics: An Empiricist's Companion}. Princeton University
Press.

\bibitem[\citeproctext]{ref-brown2022verifying}
Brown, Bradley CA, Anthony L Caterini, Brendan Leigh Ross, Jesse C
Cresswell, and Gabriel Loaiza-Ganem. 2022. {``Verifying the Union of
Manifolds Hypothesis for Image Data.''} In \emph{The Eleventh
International Conference on Learning Representations}.

\bibitem[\citeproctext]{ref-debreu1984economic}
Debreu, Gerard. 1984. {``Economic Theory in the Mathematical Mode.''}
\emph{The American Economic Review} 74 (3): 267--78.

\bibitem[\citeproctext]{ref-ferrario2022eliciting}
Ferrario, Beatrice, and Stefanie Stantcheva. 2022. {``Eliciting People's
First-Order Concerns: Text Analysis of Open-Ended Survey Questions.''}
In \emph{AEA Papers and Proceedings}, 112:163--69. American Economic
Association 2014 Broadway, Suite 305, Nashville, TN 37203.

\bibitem[\citeproctext]{ref-mighty1994fallen}
Gans, Joshua S., and George B. Shepherd. 1994. {``How Are the Mighty
Fallen: Rejected Classic Articles by Leading Economists.''}
\emph{Journal of Economic Perspectives} 8 (1): 165--79.
\url{https://doi.org/10.1257/jep.8.1.165}.

\bibitem[\citeproctext]{ref-rationality2023gilboa}
Gilboa, Itzhak, Stefania Minardi, and Fan Wang. 2023. {``{Schumpeter
Lecture 2023: Rationality and Zero Risk}.''} \emph{Journal of the
European Economic Association} 22 (1): 1--33.
\url{https://doi.org/10.1093/jeea/jvad071}.

\bibitem[\citeproctext]{ref-gilboa2014analogies}
Gilboa, Itzhak, Andrew Postlewaite, Larry Samuelson, and David
Schmeidler. 2014. {``{Economic Models as Analogies}.''} \emph{The
Economic Journal} 124 (578): F513--33.
\url{https://doi.org/10.1111/ecoj.12128}.

\bibitem[\citeproctext]{ref-theory2022gilboa}
---------. 2022. {``Economic Theory: Economics, Methods and
Methodology.''} \emph{Revue Économique} 73 (6): pp. 897--920.
\url{https://www.jstor.org/stable/48714515}.

\bibitem[\citeproctext]{ref-GILBOA20101757}
Gilboa, Itzhak, and David Schmeidler. 2010. {``Simplicity and
Likelihood: An Axiomatic Approach.''} \emph{Journal of Economic Theory}
145 (5): 1757--75.
https://doi.org/\url{https://doi.org/10.1016/j.jet.2010.03.010}.

\bibitem[\citeproctext]{ref-korinek2023gen}
Korinek, Anton. 2023. {``Generative AI for Economic Research: Use Cases
and Implications for Economists.''} \emph{Journal of Economic
Literature} 61 (4): 1281--1317.
\url{https://doi.org/10.1257/jel.20231736}.

\bibitem[\citeproctext]{ref-lucas1976econometric}
Lucas, Robert E. 1976. {``Econometric Policy Evaluation: A Critique.''}
\emph{Journal of Monetary Economics} 1 (2): 19--46.

\bibitem[\citeproctext]{ref-mei2024turing}
Mei, Qiaozhu, Yutong Xie, Walter Yuan, and Matthew O. Jackson. 2024.
{``A Turing Test of Whether AI Chatbots Are Behaviorally Similar to
Humans.''} \emph{Proceedings of the National Academy of Sciences} 121
(9): e2313925121. \url{https://doi.org/10.1073/pnas.2313925121}.

\bibitem[\citeproctext]{ref-parkes2015economic}
Parkes, David C, and Michael P Wellman. 2015. {``Economic Reasoning and
Artificial Intelligence.''} \emph{Science} 349 (6245): 267--72.

\bibitem[\citeproctext]{ref-perez2024testing}
Perez-Cruz, Fernando, and Hyun Song Shin. 2024. {``Testing the Cognitive
Limits of Large Language Models.''} Bank for International Settlements.

\bibitem[\citeproctext]{ref-intrinsic2021}
Pope, Phillip, Chen Zhu, Ahmed Abdelkader, Micah Goldblum, and Tom
Goldstein. 2021. {``The Intrinsic Dimension of Images and Its Impact on
Learning.''} \emph{CoRR} abs/2104.08894.
\url{https://arxiv.org/abs/2104.08894}.

\bibitem[\citeproctext]{ref-robbins1932essay}
Robbins, Lionel. 1932. \emph{An Essay on the Nature and Significance of
Economic Science}. Macmillan; Co., Limited.

\bibitem[\citeproctext]{ref-stantcheva2023run}
Stantcheva, Stefanie. 2023. {``How to Run Surveys: A Guide to Creating
Your Own Identifying Variation and Revealing the Invisible.''}
\emph{Annual Review of Economics} 15: 205--34.

\bibitem[\citeproctext]{ref-storks2020recent}
Storks, Shane, Qiaozi Gao, and Joyce Y. Chai. 2020. {``Recent Advances
in Natural Language Inference: A Survey of Benchmarks, Resources, and
Approaches.''} \url{https://arxiv.org/abs/1904.01172}.

\bibitem[\citeproctext]{ref-tenenbaum2000global}
Tenenbaum, Joshua B, Vin de Silva, and John C Langford. 2000. {``A
Global Geometric Framework for Nonlinear Dimensionality Reduction.''}
\emph{Science} 290 (5500): 2319--23.

\bibitem[\citeproctext]{ref-zellers2019hellaswag}
Zellers, Rowan, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
2019. {``Hellaswag: Can a Machine Really Finish Your Sentence?''}
\emph{arXiv Preprint arXiv:1905.07830}.

\end{CSLReferences}



\end{document}
