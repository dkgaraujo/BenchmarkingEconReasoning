% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage[noblocks]
{authblk}
\renewcommand*{\Authsep}{, }
\renewcommand*{\Authand}{, }
\renewcommand*{\Authands}{, }
\renewcommand\Affilfont{\small}
\DeclareMathOperator*{\argmin}{arg\,min}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{plain}
\newtheorem{proposition}{Proposition}[section]
\theoremstyle{remark}
\AtBeginDocument{\renewcommand*{\proofname}{Proof}}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\newtheorem{refremark}{Remark}[section]
\newtheorem{refsolution}{Solution}[section]
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Information acquisition in financial markets through artificial intelligence (Early stage work)},
  pdfauthor={Douglas K. G. Araujo},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Information acquisition in financial markets through artificial
intelligence (Early stage work)\thanks{This work represents my opinion
and not necessarily that of the BIS.}}


  \author{Douglas K. G. Araujo}
            \affil{%
                  Bank for International
Settlements, douglas.araujo@bis.org
              }
      
\date{}
\begin{document}
\maketitle
\begin{abstract}
Investors choose the level of costly deployment of artificial
intelligence (AI) models, such as large language models, to better
extract signal about fundamentals from a noisy and multidimensional
common data space. The monotonically increasing technology evolves over
time but both this evolution and the actual adoption depends on the use
of scarce resources, mimicking constraints in human resources and
parallel computing. Investors decide to invest on a risky asset with
strategic complementarities on information and on the level of
technology adoption by peers. The model features the possibility of
hallucinations or other silent mistakes in information processing. The
model is simple but allows inference on important topics related to the
adoption of AI in finance, including the effect of hallucinations on the
coordination of investors, the role of a closed versus open AI model,
the potentially outsized effects of cyber security or other operational
risk incidents, and supply chain shocks in the AI chip industry. JEL
codes: D82, G14.
\end{abstract}

\section{Introduction}\label{introduction}

The increasing capabilities of large language models (LLM) and modern
artificial intelligence (AI) systems more generally unlock useful new
ways to transform data into actionable information, expanding the ``data
envelope'' (Hirshlelfer (1971), Goldfarb and Tucker (2019)). These
sophisticated models have been posited to be useful even for forecasting
and stock trading (eg, Lopez-Lira and Tang (2023)), adding further
momentum to the use of these technologies. Clearly, more advanced AI
models are able to transform more data into information, improving the
precision of a signal. But other key, specific features of AI as an
information technology require new modelling tools that are not found in
existing frameworks of endogenous information acquisition in incomplete
games (eg, Hellwig and Veldkamp (2009), M. Yang (2015), Szkup and
Trevino (2015b)). First, AI models can also output erroneous content
that may be hard to identify, such as seemingly-correct
``hallucinations'' (Alkaissi and McFarlane (2023), Ji et al. (2023)), an
issue that is compounded by the inescrutable nature of these models. For
example, LLMs might provide human-like answers that fail to correctly
identify trivial aspects of tasks (Perez-Cruz and Shin (2024)). Second,
the AI technology is still evolving at a fast pace (eg, J. Yang et al.
(2023)), which itself might change the information acquisition
calculation of agents as they expect a certain chance that current
models will be nondecreasingly more powerful. In this paper, the AI
resources not used by agents is made available to technologists, who
then try to improve AI technology subject to resource availability. All
of this on top of the usually modelled costs to acquire information,
which in this case represent the limited AI-specific resources such as
skilled labour force and adequate chips that are limited.

The main contribution of this paper is to set up a simple but flexible
model of endogenous information acquisiton under incomplete information,
subject to bias in the private signal (from the ``AI hallucinations'')
and to stochastic technological breakthrough that improves the model's
reasoning, tapering the hallucinations. Other than these AI-specific
parameterisations, the model follows a standard information acquisition
model that can be solved as a global game (Carlsson and Van Damme
(1993), Morris and Shin (2003)), yielding a symmetric, unique
equilibrium outcome. This baseline model is used to show that the
equilibrium choices of AI resource take-up by investors facing a risky
payoff are consistent with the level of AI that minimises bias in the
private signal. In other words, investors invest the ``right'' amount in
AI for their application at hand, even if the investment decision itself
is risk- and not payoff-dominant (Harsanyi and Selten (1988)).

The baseline 2-investor game plays out in two stages. In the \emph{AI
investment} stage, each investor \(i\) chooses how much of their
endowment \(E\) will be allocated to acquiring AI-related resources (eg,
skilled practitioners, graphics processing unit chips - GPU) from a
limited pool \(R\). The remainder after the investors decide their AI
investment is available to technologists, and will influence
technological development: \(R = R_{AI} + \sum_i R_i\). Next, the
\emph{financial investment} stage entails a binary investment decision
on the remainder of the endowment, \(I_i = E - R_i\). The payoff depends
on an unobserved state \(\theta\) and, for intermediate levels of the
fundamental outcome, on coordination between investors. These decisions
are taken after each investor observes a private signal that depends
non-linearly on the level of AI investment: higher AI amounts increase
precision in the private signal, but expose the investor to AI
hallucinations. These latter elements are additive biases in the private
signal that behave exponentially, like a ``hockey stick'' line, kicking
off strongly at high levels of AI adoption. A final unknown component in
the model is the degree of technological advance in between stages.
Technologists take the remainer of the resources, \(R_{AI}\), and use it
to implement research ideas that are compared with obstacles. Whenever
these are net positive, the hallucinations taper off. This represents
for example advances in reasoning ability (Douglas K. G. Araujo (2024))
or in fine-tuning to make models.

A unique value of AI investment minimises the bias in the private
signal, ie optimally balances the hallucination with the
precision-increasing effects of greater investment in AI. Interestingly,
even as the equilibrium definition is not conditional on an optimal
first-stage allocation, this happens to be the value that is consistent
with the second-stage equilibrium. The model is simple enough to
represent the main dynamics of investors' indirect acquisition of
information through their investment in AI. At the same time, it
contains rich enough representations that allow the study of questions
of interest. In this paper I explore three of them. First, the baseline
specification speaks to AI's ability to reason. One of the extensions,
studying the effect of an eventual much-hyped artificial general
intelligence (AGI), simply involves turning off the hallucination. The
third extension addresses current policy and academic discussions around
the wisedom of openly available versus closed models. Secondly, the
model can be slightly adapted to study the potentially outsized effects
of cyber security or other operational risk incidents, including issues
related to AI vendor concentration.

\subsection{Literature}\label{literature}

This work relates to the literatures on information acquisition in
incomplete information games, and on AI and data in finance. The class
of global games models address incomplete information settings Carlsson
and Van Damme (1993). Morris and Shin (2002), Morris and Shin (2003). A
second stream of papers related to this work discuss endogenous
information acquisition, similar to the current paper.
\textbf{Coordination with information acquisition}. Angeletos and Lian
(2016), Szkup and Trevino (2015b), Szkup and Trevino (2015a), Szkup and
Trevino (2021). Reshidi et al. (2021) study the individual and
collective information acquisition. Technology adoption canonical model
D. Frankel and Pauzner (2000). Private aquisition of information
(processing), Hellwig and Veldkamp (2009) and Colombo, Femminis, and
Pavan (2014). Colombo, Femminis, and Pavan (2014) highlights the
difference between effiencies in information acquisition and its usage.
In contrast with that literature, here the AI technology frontier also
develops endogenously and responds (negatively) to the resource take-up
from technology adoption.

Another stream of papers discusses \textbf{data in finance}: Farboodi et
al. (2022) models the extraction by investors of \emph{information} on
assets from \emph{data}, and how the value of data is related also to
characteristics of the asset itself. Begenau, Farboodi, and Veldkamp
(2018) argues that the existence of more data to larger firms favours
them over others. And a more specific line of works examines \textbf{AI
in finance, including associated risks.} AI can read information better
(Douglas Kiarelly Godoy Araujo et al. (n.d.), Douglas Kiarelly Godoy
Araujo et al. (2024)), and especially the more sophisticated type of
models - large language models (LLMs) can further increase the ability
to use data (Korinek (2023)). Lopez-Lira and Tang (2023) show evidence
that ChatGPT, the flagship LLM, can successfully pick stocks.
Danielsson, Macrae, and Uthemann (2022) discuss risks. Increased
availability of data (Veldkamp and Chung (2019)) and lower cost across
data pipeline (Goldfarb and Tucker (2019)). This facilitates the use of
new data, or data in a compound way, due to the ``discovery'' of new
data by newer technologies Hirshlelfer (1971). An early reference is
Ranco et al. (2015). New techniques not only process more data more
effectively, but they also expand the envelope of data that can be
analysed to look for signal.

\section{Model}\label{model}

The model draws heavily from the setup in Szkup and Trevino (2021), with
important additions that represent key features of AI as an information
technology. Second, the technology itself evolves stochastically over
time, including in response to factor prices as well. And third, the
process by which AI improves the signal is laid out in more detail to
highlight the cases where the technology can transform more data text
into inormation but cannot yet \emph{reason} about it.

\subsection{Setup}\label{setup}

The simplest version of the model is a two-investor setup as follows.

The state of economic fundamentals is a random variable with normal
distribution \(\theta \sim N(\mu_\theta, \sigma_\theta^2)\). \(\theta\)
is only observed indirectly by each investor \(i\) as a noisy signal,
\(x_i = \theta + \sigma_i \epsilon_i\). An AI technology
\(\alpha(R) > 0\) uses finite specialised resources \(R\) (eg, AI
scientists, data engineers, graphics processing units chips - GPUs, etc)
to improve the precision of the signal of the existing data. The total
amount of these resources is divided into AI developers and the
investors: \(R = R_{\text{AI}} + \sum_{i} R_i\) for
\(R_{\text{AI}} > 0\) and \(\forall R_i \geq 0\). The technology has
decreasing returns to scale with \(\alpha_R' > 0, \alpha_R'' < 0\), and
each individual precision defined as
\(\sigma_i = \sigma / \alpha(R_i)\). \(\alpha\) itself is common amongst
players, reflecting the current relevance of open source and open weight
models in the high end AI market. However, section
Section~\ref{sec-closedmodels} relaxes this definition so that investors
can also purchase a unique \(\alpha_i\) technology.

However, unless the AI model can actually reason, very precise signals
(low \(\sigma_i\)) also increase the risk of belieavable wrong answers
(such as ``hallucinations'') or other forms of ``silent mistakes'',
which bias the investor's perception about fundamentals. Such a problem
is of course compounded by the high confidence the investor has in the
signal given its acquired low \(\sigma_i\). This is modelled through a
\emph{reasoning filter} \(\phi\) (see \textbf{?@sec-reasoning}). This
function is the identity function if the AI cannot reason and 0 if it
can reason. Having \(\eta \sim N(0, \sigma_\eta)\) as the baseline level
of noise\footnote{Reflecting, for example, technology frictions in the
  production and dissemination of data, or more fundamentally even the
  sparsity in the actual signal from the manifold hypothesis.} for all
private signals, then each investor will observe
\(\epsilon_i = \eta + \phi(e^{\lambda \alpha_i(R)})\), in which
\(\lambda\) is an inconsequential positive constant for scaling only.
Putting all of this together, the private signal about the fundamentals
is:

\begin{equation}\phantomsection\label{eq-privatesignals}{
x_i = \theta + (\eta + \phi(e^{\lambda \alpha(R_i)})) \sigma / \alpha(R_i)
}\end{equation}

Given this scenario for technology investment, two ex ante identical
investors \(i \in \{1,2\}\) choose how much \(R_i\) to acquire. Because
resources are finite and technologists pick up the residual resources
not acquired by investors, the investors face a supply curve and the
technologists are assumed for simplicity to be price takers. Given this
structure, prices are normalised as the proportion of resources taken by
investors, \(\rho = (1/R)\sum_i R_i\).\footnote{The actual prices could
  be proportional to this ratio, but the added clutter to notation does
  not justify it.}. The prices are public information and the market for
AI resources clear.

The two investors decide in the first stage how much of their endowment
to invest in AI usage, with the remainder available for the next stage
where they decide whether or not to invest, \(a_i \in \{0, 1\}\). This
equality is represented as \(E_i = R_i + I_i\). In the second period,
the investors decide how to allocate \(I_i\), in a safe or risky asset
(the allocation is binary). The safe asset does not have a cost, and
yields zero regardless of \(\theta\) or the number of investors who
choose it. Conversely, the risk asset's payoff can be successful in
either of the following situations: (a) if \(\theta \geq \bar{\theta}\)
or (b) if \(\theta \geq \underline{\theta}\) and \(A_i = A_j = 1\).
While this payoff structure follows Szkup and Trevino (2021) closely,
the current model differs from that one because investors only allocates
\(I_i\). Because investing in the risky asset entails a cost \(T\), the
risky asset yields \(\theta I_i - T\) in case of success or
alternatively, \(-T\).

Each investor's choice \(a_i\) depends on the observed signal \(x_i\)
and the level of use of AI chosen in the preceding step, \(R_i\). As in
Szkup and Trevino (2021), the level of precision (from the investment in
AI resources) is common knowledge in this simple game, but here it is
only incidentally so: this settings comports only two investors and a
common price that reflects their joint AI investments.\footnote{A richer
  setting would see not only more investors, including atomic ones, but
  also have only the global AI resource expense be public, not its
  distribution to investors. The type of challenge it would bring to the
  current model includes for example a non-trivial correlation between
  the use of AI and the perceived signal. This interesting case demands
  a dedicated exposition and not further dealt with in this paper.} Each
investor's utility is a mapping of the form
\(u : \{0, 1\} \times \{0, 1\} \times \mathbf{R} \times [0, 1] \to \mathbf{R}\),
with \(u(A_i, A_j, x_i, R_i)\) representing investor \(i\)'s pay-off as
a function of their own action, the other investor's action, the signal
observed by \(i\), and its investment in the AI technology.

In concrete terms,

\begin{equation}\phantomsection\label{eq-utility}{
u(A_i, A_j, x_i, R_i) = (\mathbf{1}[\theta \geq \bar{\theta}|x_i] + \mathbf{1}[x_i \geq x_i^*|\theta]a_j)a_i(\theta I_i - T) - R_i,
}\end{equation}

from which the indifference threshold with respect to investing or not
investing depending on the signal is set. {[}to add, equilibrium{]}

Innovations in AI reasoning happen in between periods: after investors
have decided \(\rho\), the remainder \(R_{\text{AI}}\) determines the
probability of a major breakthrough in reasoning ability. This is
modelled as follows.\footnote{Recall that \(\phi\) determines the
  reasoning ability in a way that is orthogonal to model performance.}
Two independent random draws from U(0, 1),
\(\pi_{\text{idea}}, \pi_{\text{obstacle}}\), correspond respectively to
innovative ideas and to practical obstacles to innovation related to
those ideas. The idea requires resources for implementation, and thus a
technological advance only happens if the idea, once actually
implemented, overcomes the barrier to innovation. Formally:

\begin{equation}\phantomsection\label{eq-tech}{
\phi = 1-\text{max}(0, \underbrace{\pi_{\text{idea}} * (1-\rho)}_{\text{Implemented idea}} - \pi_{\text{obstacle}}).
}\end{equation}

\(\phi\) tapers off the noisiness to help the private signal get closer
to \(\theta + \eta\). Note that the only chance of a full shutdown of
the added noise by the AI model - for example, through the concept of
\emph{artificial generalised intelligence}, is ruled out and would
require all of the AI-related resources to the technologists only.

One important observation about the effect of AI on financial
investments is consistent with a classical result in the global games
literature (Morris and Shin (2002), Morris and Shin (2003)): the price
\(\rho\) of AI resources has an outsized impact on outcomes by virtue of
its public nature.

\subsection{Equilibrium in financial and AI
investments}\label{equilibrium-in-financial-and-ai-investments}

After the decisions to invest in AI is taken, the second stage involves
an investment in the financial asset. This step resembles a traditional
global game (Morris and Shin (2003)), but where players choose the
precision of their own information as in, for example, M. Yang (2015),
Szkup and Trevino (2021). The tendency of the game to a unique outcome,
due to the limit uniqueness (D. M. Frankel, Morris, and Pauzner (2003)).

First, note there is exactly one value of \(\alpha(R_i)\) that results
in an minimally biased private signal.

\begin{proposition}[AI use with minimal bias in private
signal]\protect\hypertarget{prp-alphainvestlowestbias}{}\label{prp-alphainvestlowestbias}

There is only one specific value \(\alpha^* = \alpha(R^*)\) for which
the private signal is the closest to \(\theta\) in expectation. The
subscript is irrelevant because all investors are ex ante similar.

\end{proposition}

\begin{proof}
The first order condition only holds for one value of \(\alpha > 0\).
Starting with the first derivative, \[
\frac{d}{d \alpha^*} (\eta + \phi e^{\lambda \alpha^*}) \sigma / \alpha^* = 0
\]

the expression can be manipulated to facilitate isolating \(\alpha^*\)
in the numerator to the left side:

\[
\frac{\phi \lambda e^{\lambda \alpha^*} \sigma}{\alpha^*} - \frac{\phi e^{\lambda \alpha^*}\sigma}{(\alpha^*)^2} = \frac{\eta \sigma}{(\alpha^*)^2}.
\]

Multiplying both sides by \((\alpha^*)^2\) obtains

\[
\alpha^* \lambda \phi e^{\lambda \alpha^*} \sigma - \phi e^{\lambda \alpha^*}\sigma = \eta \sigma,
\]

which is the same as

\[
\phi e^{\lambda \alpha^*} (\lambda \alpha^* - 1)= \eta,
\]

and thus if \(\phi > 0\), the only possible solution with a positive
value is \(\alpha^* = 1/\lambda\).

The second derivative obtained by substituting this equality above is
positive, confirming that \(\alpha^*\) minimises the bias on the signal.

\[
\frac{d^2}{d (1/\lambda)^2} (\eta + \phi e) \sigma \lambda = (\sigma \lambda^2 \phi e + \sigma \lambda \phi e)\lambda^3 \\
\]
\end{proof}

Proposition~\ref{prp-alphainvestlowestbias} highlights the problem with
AI investment as a technology to process information: optimising on
precision alone (lowering \(\sigma_i\)) exposes the investors to more
biases in the signal at very high levels of technology adoption. Higher
levels of \(R_i\) monotonically increase precision but there is only one
level of \(R\) that minimises bias in information.

Note also that it seems to be a repetition of the classical
bias-variance trade-off (BVTO) but it is in fact a different phenomenon.
BVTO implies that more flexible and complex models would lead to lower
bias and high out-of-sample variance, as more sophisticated models
obtain a better fit to existing data at the risk of not generalising too
well. The current setting shines a light on a different problem that
incorporates economic and information- and game-theoretic elements: even
if the model obtains lower variance by usefully increasing out-of-sample
precision (real life examples include the ability to digest unstructured
data such as text to improve signal pickup), the fact it \emph{can}
hallucinate and at the same time is increasingly trusted both by its
practicality and precision, introduces uncertainty in the model.

\section{Equilibrium}\label{equilibrium}

Note that similar to Szkup and Trevino (2021), the investment stage can
resemble a global game, only with investors that are potentially
heterogeneous on their private signals. So I follow standard practice in
global games and find the equilibrium strategies based on a signal
\(x_i^*(R_i)\) that would lie at the investment indifference threshold
for investor \(i\):

\[
A(R_i, x_i) = \mathbf{1}[x_i \geq x_i^*(R_i)].
\]

Finding this threshold entails equating Equation~\ref{eq-utility} with
zero under the investment scenario, ie \(A(R_i, x_i)=1\), and then
solving for \(x_i^*(R_i)\):

\begin{equation}\phantomsection\label{eq-equilinvest}{
E[Pr(A_j(\theta)=1)\theta I_i | x_i = x_i^*, \theta \in [\underline{\theta}, \bar{\theta}] ] + E[\theta I_i |x_i = x_i^*, \theta > \bar{\theta} ] = T,
}\end{equation}

where \(E[Pr(A_j(\theta)=1)]\) is the expected (by \(i\)) probability
that \(j\) has invested in the asset given the fundamental. The first
term on the left is the expected success payout in the intermediate
fundamentals case, which requires coordination. The second term is the
expected success in the good fundamentals scenario.

The equilibrium is due to Szkup and Trevino (2021), who extend the
monotone supermodular games result from Van Zandt and Vives (2007) in
games with unbounded utility functions. In particular, Szkup and Trevino
(2021) show that there exist both a least and a greatest bounds in
Bayesian Nash equilibra, and that these thresholds correspond to a
univalent mapping to a unique outcome.

\section{Equilibrium}\label{equilibrium-1}

The equilibrium is found by backward induction, starting with the
financial investment stage. Collect the allocations of \(R\) in
\(r=\{R_i, R_j, R_{AI}\}\). Investor strategies
\(A : \mathbb{R} \times [0,1]^3 \times (0,1]\to \{0,1\}\) map the
private signal, the allocation \(r\) and the AI reasoning ability
\(\phi\) to a binary investment decision, where \(1\) is associated with
the investing choice. Using the global games' threshold strategies and
the uniquess of equilibrium outcomes due to Szkup and Trevino (2021)
extending the results from Van Zandt and Vives (2007), the investor
decides to invest if the private signal is higher than a specific
threshold, as in

\begin{equation}\phantomsection\label{eq-strategies}{
A(x_i;r;\phi) = \mathbf{1}[x_i \geq x_i^*(r, \phi)].
}\end{equation}

The value \(x_i^*\) in Equation~\ref{eq-strategies} that makes the
investor indifferent to investing or not investing is the optimal
threshold. The following specification considers both the scenario in
which fundamentals are intermediate and the investment requires
coordination, and the scenario in which fundamentals are good enough
that success does not necessitate coordination. The equation

\begin{equation}\phantomsection\label{eq-optimthresh}{
E[\theta I_i \text{Pr}(A_j(\theta) = 1)|x_i = x_i^*, \theta \in [\underline{\theta}, \bar{\theta})] + E[\theta I_i|x_i = x_i^*, \theta \geq \bar{\theta}] = T
}\end{equation}

represents the situation where the expected payoff of an \(I_i\)
investment is set to zero. Now moving backwards to the AI investment
stage, consider \(\nu_i(\cdot)\) as the expected investment payoff to
\(i\) afer observing their own private signal \(x_i\) and believing that
investor \(j\) will also optimise. Consider also a belief function
\(\mu_i : [0, 1] \to [0, 1]\) as \(i\)'s belief on the probability that
\(j\) chose a specific value of \(R_j\). In general terms, the expected
utility of each investor is:

\begin{equation}\phantomsection\label{eq-expectedutil}{
U_i(r) = E[\mathbf{1}[x_i \geq x_i^*(e, \phi)] \nu_i(x_i, xj^*(r, \phi); r)]f(x_i;R_i, \phi)dx_i.
}\end{equation}

All elements to define the equilibrium are now in place.

\begin{definition}[Pure strategy Bayesian Nash
equilibrium]\protect\hypertarget{def-equilibrium}{}\label{def-equilibrium}

A vector of AI investment allocations
\(r^* = \{R_i^*, R_j^*, R_{AI}^*\}\), belief function \(\mu_i\), and
optimal financial investment decision \(A_i(x_i;r;\phi)\) is a pure
streategy Bayesian Nash equilibrium if, for each \(i \in \{1,2\}\), it
complies with the conditions below:

\textbf{C1 - no incentives to deviate}.
\(U_i(r^*) \geq U_i(r') \forall r' \neq r^*\),

\textbf{C2 - correct strategic anticipation}.
\(\mu_i(R_j^*)=1, \mu_i(R_j^{'}) = 0, r' \neq r^*\); and

\textbf{C3 - optimal financial investment even if sub-optimal AI
investment}.

\[
A(x_i;r;\phi) = \mathbf{1}[x_i \geq x_i(\{R_i, R_j^*, R_{AI}\}, \phi)], \text{s.t.  }
\] \[
x_i^* \in \{x_i : \nu(x_i(\{R_i, R_j^*, R_{AI}\}, \phi), x_j^*(r^*, \phi); r) = 0 \}
\]

\end{definition}

The first condition, C1, lays out that no investor has an incentive to
deviate from the equilibrium because they will not extract a higher
utility. C2 is necessary to ensure that the equiibrium obtains from a
situation that each investor assigns positive probability to the amounts
of AI investment that the other investor would choose. And the third
condition pins down the idea that the signal threshold associated with
the investment action can also be associated with of each investors' own
AI investment that is not necessarily the optimal.

\begin{proposition}[Equilibrium]\protect\hypertarget{prp-equilibrium}{}\label{prp-equilibrium}

The equilibrium as defined in Definition~\ref{def-equilibrium} exists
and is unique.

\end{proposition}

\subsection{Information-efficient use of
AI}\label{information-efficient-use-of-ai}

In the base scenario that AI models do not reason robustly, they always
let at least \emph{some} hallucination pass through (\(\phi > 0\)). A
natural question is whether the value of AI investment that minimises
bias in the private signal (from
Proposition~\ref{prp-alphainvestlowestbias}) is consistent with the
equilibrium outcomes. The following exercise focuses on the case of
intermediate fundamental values, as they require coordination for
success.

Define \(r^§ = \{R_i^§, R_j^*, R_{AI}^§\}\) as a the AI investment by
investor \(i\) driven only by their need to optimise the private signal,
while \(j\) continues to allocate their investment according to the
full-game perspective. Assume C2 and C3 of
Definition~\ref{def-equilibrium} hold. Then it suffices to check if C1
still holds, but with \(r^§\). In particular, whether:

\[
E[\theta I_i^§ \text{Pr}(A_j(\theta)=1) | x_i = x_i*, \theta \in [\underline{\theta}, \bar{\theta})]] = E[\theta I_j^* \text{Pr}(A_i(\theta)=1) | x_j = x_j*, \theta \in [\underline{\theta}, \bar{\theta})]].
\]

Factoring out the common expectation components related to \(\theta\),
we have:

\[
I_i^§ \text{Pr}(A_j(\theta)=1) = I_j^* \text{Pr}(A_i(\theta)=1),
\]

which are the same since the equilibrium values are robust to AI
investment misspecification (C3), and therefore the right hand side
stays the same. Since \(I_i^§ > 0\) the equation still holds, and from
the threshold strategies, the two probabilities are equal, thus also
\(I_i^§ = I_j^*§*\), confirming the value of \(r\) that is consistent
with the equilibrium outcome is \(r^* = r^§\).

\section{Open vs closed models}\label{sec-closedmodels}

What is the influence, if any, of the possibility of investors to use
exclusive, closed models to the equilibrium outcomes laid out above?
This section relaxes the definition of \(\alpha\) to allow for the
possibility that investors spend some money in the first period to
acquire or develop such models.

Assume that the development of a closed-model entails a cost \(C > 0\)
whereas the use of a public-knowledge open model is free (consistent
with real life). In this case, then investors would choose the
closed-model if \(\alpha_i(R_i) > \alpha(R_i)\) and the final net payoff
would still be positive even with the safe.

\section{Operational risks (eg, cyber disruptions and AI vendor
dependence)}\label{operational-risks-eg-cyber-disruptions-and-ai-vendor-dependence}

Suppose now that \(\alpha\) has a small but nonzero chance of being set
to zero during the investment stage. Such a scenario would be akin to an
operational risk incident, such as a cyber attack. Building on financial
supervisors' work on risks from third party service providers, such as
AI providers,\footnote{For example, the Basel Committee on Banking
  Supervision recently (2022) exorted banks to address risks related to
  concentration of third party service providers.} this section explores
AI shutdown effects that are proportional to \(\rho\).

Take Equation~\ref{eq-privatesignals}, but now assume that \(\mu\) is a
constant that always multiplies \(\alpha\). The constant goes to zero
with probability \(\rho\), representing an operational incident.

\section[Preliminary considerations]{\texorpdfstring{Preliminary
considerations\footnote{This section will become the conclusion section.}}{Preliminary considerations}}\label{preliminary-considerationsconcl}

AI is not simply a generic information technology. In addition to
resource distribution considerations, introducing the use of AI to
process information entails both an increase in precision (in line with
existing information acquisition models), but also changes that reflect
hallucinations and other silent mistakes and a chance for stochastic
technology improvements that agents may expect to take place.

The present model is simple but sufficiently rich to enable studies of
important phenomena of interest at the intersection of AI and finance.
For example, this model can help estimate the effects of hallucinations,
operational risk issues, welfare implications from closed vs open models
and others.

The joint determination in equilibrium of AI investment in finance
industry and academia, together with the levels and returns of financial
investments, bear interesting results. This paper shows that the global
game results in AI take-up that is consistent with the minimisation of
private noise in expectation. This is an interesting result because the
game-level result itself is the risk-dominant strategy, not the most
efficient payoff-dominant.

\section{Discussion}\label{discussion}

The idea that the market might overreact to the knowledge about
deployment of AI by firms is not new (Morris and Shin (2002)).

More broadly, this model extends the work of Szkup and Trevino (2015b).
That paper establishes important results with respect to the symmetric
nature of the outcome of games that allow for information aquisition,
and the relatively amenable conditions under which equilibrium is
unique.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-alkaissi2023artificial}
Alkaissi, Hussam, and Samy I McFarlane. 2023. {``Artificial
Hallucinations in ChatGPT: Implications in Scientific Writing.''}
\emph{Cureus} 15 (2).

\bibitem[\citeproctext]{ref-angeletos2016incomplete}
Angeletos, G-M, and Chen Lian. 2016. {``Incomplete Information in
Macroeconomics: Accommodating Frictions in Coordination.''} In
\emph{Handbook of Macroeconomics}, 2:1065--1240. Elsevier.

\bibitem[\citeproctext]{ref-Araujo2024reason}
Araujo, Douglas K. G. 2024. {``Benchmarking Economic Reasoning in
Artificial Intelligence Models.''}

\bibitem[\citeproctext]{ref-araujo2023data}
Araujo, Douglas Kiarelly Godoy, Giuseppe Bruno, Juri Marcucci, Rafael
Schmidt, and Bruno Tissot. n.d. {``Data Science in Central Banking:
Applications and Tools.''}

\bibitem[\citeproctext]{ref-araujo2024artificial}
Araujo, Douglas Kiarelly Godoy, Sebastian Doerr, Leonardo Gambacorta,
and Bruno Tissot. 2024. {``Artificial Intelligence in Central
Banking.''}

\bibitem[\citeproctext]{ref-bcbs2022tpsp}
Basel Committee on Banking Supervision. 2022. {``{Newsletter on Third-
and Fourth-Party Risk Management and Concentration Risk}.''} {Bank for
International Settlements}. \url{https://www.bis.org}.

\bibitem[\citeproctext]{ref-begenau2018big}
Begenau, Juliane, Maryam Farboodi, and Laura Veldkamp. 2018. {``Big Data
in Finance and the Growth of Large Firms.''} \emph{Journal of Monetary
Economics} 97: 71--87.

\bibitem[\citeproctext]{ref-carlsson1993global}
Carlsson, Hans, and Eric Van Damme. 1993. {``Global Games and
Equilibrium Selection.''} \emph{Econometrica: Journal of the Econometric
Society}, 989--1018.

\bibitem[\citeproctext]{ref-colombo2014information}
Colombo, Luca, Gianluca Femminis, and Alessandro Pavan. 2014.
{``Information Acquisition and Welfare.''} \emph{The Review of Economic
Studies} 81 (4): 1438--83.

\bibitem[\citeproctext]{ref-danielsson2022artificial}
Danielsson, Jon, Robert Macrae, and Andreas Uthemann. 2022.
{``Artificial Intelligence and Systemic Risk.''} \emph{Journal of
Banking \& Finance} 140: 106290.

\bibitem[\citeproctext]{ref-farboodi2022has}
Farboodi, Maryam, Adrien Matray, Laura Veldkamp, and Venky
Venkateswaran. 2022. {``Where Has All the Data Gone?''} \emph{The Review
of Financial Studies} 35 (7): 3101--38.

\bibitem[\citeproctext]{ref-frankel2003equilibrium}
Frankel, David M, Stephen Morris, and Ady Pauzner. 2003. {``Equilibrium
Selection in Global Games with Strategic Complementarities.''}
\emph{Journal of Economic Theory} 108 (1): 1--44.

\bibitem[\citeproctext]{ref-techadoption}
Frankel, David, and Ady Pauzner. 2000. {``{Resolving Indeterminacy in
Dynamic Settings: The Role of Shocks*}.''} \emph{The Quarterly Journal
of Economics} 115 (1): 285--304.
\url{https://doi.org/10.1162/003355300554746}.

\bibitem[\citeproctext]{ref-goldfarb2019digital}
Goldfarb, Avi, and Catherine Tucker. 2019. {``Digital Economics.''}
\emph{Journal of Economic Literature} 57 (1): 3--43.

\bibitem[\citeproctext]{ref-harsanyi1988general}
Harsanyi, John C, and Reinhard Selten. 1988. {``A General Theory of
Equilibrium Selection in Games.''} \emph{MIT Press Books} 1.

\bibitem[\citeproctext]{ref-hellwig2009knowing}
Hellwig, Christian, and Laura Veldkamp. 2009. {``Knowing What Others
Know: Coordination Motives in Information Acquisition.''} \emph{The
Review of Economic Studies} 76 (1): 223--51.

\bibitem[\citeproctext]{ref-hirshlelfer1971private}
Hirshlelfer, Jack. 1971. {``The Private and Social Value of Information
and the Reward to Inventive Activity.''} \emph{The American Economic
Review} 61 (4): 561--74.

\bibitem[\citeproctext]{ref-ji2023survey}
Ji, Ziwei, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko
Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. {``Survey of
Hallucination in Natural Language Generation.''} \emph{ACM Computing
Surveys} 55 (12): 1--38.

\bibitem[\citeproctext]{ref-korinek2023gen}
Korinek, Anton. 2023. {``Generative AI for Economic Research: Use Cases
and Implications for Economists.''} \emph{Journal of Economic
Literature} 61 (4): 1281--1317.
\url{https://doi.org/10.1257/jel.20231736}.

\bibitem[\citeproctext]{ref-lopez2023can}
Lopez-Lira, Alejandro, and Yuehua Tang. 2023. {``Can Chatgpt Forecast
Stock Price Movements? Return Predictability and Large Language
Models.''} \emph{arXiv Preprint arXiv:2304.07619}.

\bibitem[\citeproctext]{ref-morris2003global}
Morris, Stephen, and HS Shin. 2003. {``Global Games: Theory and
Applications. Advances in Economics and Econometrics, m Dewatripont, l
Hansen, and s Turnovsky.''} Cambridge University Press, NY.

\bibitem[\citeproctext]{ref-morris2002social}
Morris, Stephen, and Hyun Song Shin. 2002. {``Social Value of Public
Information.''} \emph{American Economic Review} 92 (5): 1521--34.

\bibitem[\citeproctext]{ref-perez2024testing}
Perez-Cruz, Fernando, and Hyun Song Shin. 2024. {``Testing the Cognitive
Limits of Large Language Models.''} Bank for International Settlements.

\bibitem[\citeproctext]{ref-ranco2015effects}
Ranco, Gabriele, Darko Aleksovski, Guido Caldarelli, Miha Grčar, and
Igor Mozetič. 2015. {``The Effects of Twitter Sentiment on Stock Price
Returns.''} \emph{PloS One} 10 (9): e0138441.

\bibitem[\citeproctext]{ref-reshidi2021individual}
Reshidi, Pëllumb, Alessandro Lizzeri, Leeat Yariv, Jimmy H Chan, and
Wing Suen. 2021. {``Individual and Collective Information Acquisition:
An Experimental Study.''} National Bureau of Economic Research.

\bibitem[\citeproctext]{ref-szkup2015informationtr}
Szkup, Michal, and Isabel Trevino. 2015a. {``Information Acquisition and
Transparency in Global Games.''} \emph{Journal of Economic Theory} 160:
387--428.

\bibitem[\citeproctext]{ref-szkup2015informationgg}
---------. 2015b. {``Information Acquisition in Global Games of Regime
Change.''} \emph{Journal of Economic Theory} 160: 387--428.

\bibitem[\citeproctext]{ref-szkup2021information}
---------. 2021. {``Information Acquisition and Self-Selection in
Coordination Games.''} mimeo.

\bibitem[\citeproctext]{ref-van2007monotone}
Van Zandt, Timothy, and Xavier Vives. 2007. {``Monotone Equilibria in
Bayesian Games of Strategic Complementarities.''} \emph{Journal of
Economic Theory} 134 (1): 339--60.

\bibitem[\citeproctext]{ref-veldkamp2019data}
Veldkamp, Laura, and Cindy Chung. 2019. {``Data and the Aggregate
Economy.''} \emph{Journal of Economic Literature}.

\bibitem[\citeproctext]{ref-yang2023harnessing}
Yang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng,
Haoming Jiang, Bing Yin, and Xia Hu. 2023. {``Harnessing the Power of
LLMs in Practice: A Survey on Chatgpt and Beyond.''} \emph{arXiv
Preprint arXiv:2304.13712}.

\bibitem[\citeproctext]{ref-yang2015coordination}
Yang, Ming. 2015. {``Coordination with Flexible Information
Acquisition.''} \emph{Journal of Economic Theory} 158: 721--38.

\end{CSLReferences}



\end{document}
